{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM's Python Project for Data Engineering\n",
    "\n",
    "This project is part of the IBM Data Engineering Professional Certificate. It is intended for learners to apply basic Python knowledge to Extract, Transform and Load (ETL) data.\n",
    "\n",
    "In this short course I've used Skills Network Labs's Cloud IDE as environment and I've used Python to write the code. Since Cloud IDE is not a persistent platform, I've saved a copy on my local machine and edited the code on Visual Studio Code, changing file paths accordingly to make it work. \n",
    "I've used Jupyter Notebook in order to show and explain the process.\n",
    "\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "The aim is to create a code that generates a dataframe containing the top 10 largest banks in the world ranked by market capitalization in billion USD. \n",
    "The data needs to be transformed and stored in GBP, EUR and INR as well. The dataframe is to be saved locally in a CSV format and as a database table.\n",
    "\n",
    "Task 1:\n",
    "Write a function to create log entries and save them in a txt file.\n",
    "\n",
    "Task 2:\n",
    "Perform web scraping with BeautifulSoup. Inspect the HTML code from the given URL, extract information from the table under the heading 'By market capitalization' and save it to a dataframe.\n",
    "Write a function to perform the required data extraction.\n",
    "\n",
    "Task 3:\n",
    "Write a function to transform the dataframe by adding columns for Market Capitalization in GBP, EUR and INR, rounded to 2 decimal places, based on the exchange rate information shared as a CSV file.\n",
    "\n",
    "Task 4:\n",
    "Write a function to load the transformed dataframe to an output CSV file.\n",
    "\n",
    "Task 5:\n",
    "Write a function to load the transformed dataframe to an SQL database server as a table. \n",
    "\n",
    "Task 6:\n",
    "Run queries on the database table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data URL is https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\n",
    "The exchange rate CSV file path is https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\n",
    "\n",
    "## Preliminaries\n",
    "Before building the code, I need to install the required libraries.\n",
    "\n",
    "The libraries needed for the code are:\n",
    "\n",
    "`requests` - The library used for accessing the information from the URL.\n",
    "\n",
    "`bs4` - The library containing the BeautifulSoup function used for webscraping.\n",
    "\n",
    "`pandas` - The library used for processing the extracted data, storing it in the required formats, and communicating with the databases.\n",
    "\n",
    "`numpy` - The library required for the mathematical rounding operations.\n",
    "\n",
    "`sqlite3` - The library required to create a database server connection.\n",
    "\n",
    "`datetime` - The library containing the function datetime used for extracting the timestamp for logging purposes.\n",
    "\n",
    "While the modules `requests`, `sqlite3` and `datetime` are part of the Python standard library, I need to install the other required libraries from the terminal window.\n",
    "\n",
    "Therefore, I run the following code on the terminal:\n",
    "\n",
    "`pip install bs4`\n",
    "`pip install pandas`\n",
    "`pip install numpy`\n",
    "\n",
    "From the terminal, I also need to download the required exchange rate file. I use the `cd` command to change directory, then run the following command:\n",
    "\n",
    "`wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv`\n",
    "\n",
    "Finally, I import the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the libraries I need, I create some variables:\n",
    "- the URL I need to extract information from\n",
    "- a list of attributes of the column names for the dataframe, one is the name of the bank and one is the Market capitalization in billion USD as listed in the table of interest from the webpage\n",
    "- a list of attributes for the final dataframe, containing also the GBP, EUR and INR fields\n",
    "- the database name\n",
    "- the table name\n",
    "- the target CSV file path \n",
    "- the log txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "table_attribs_final = [\"Name\", \"MC_USD_Billion\", \"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"] \n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = './Largest_banks_data.csv'\n",
    "log_file = 'code_log.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Logging function\n",
    "Write the function to log the progress of the code, `log_progress()`. The function accepts the message to be logged and enters it to a text file `code_log.txt`.\n",
    "\n",
    "The format to be used for logging must have the syntax:\n",
    "`<time_stamp> : <message>`\n",
    "\n",
    "Each log entry must happen in the next line in the text file.\n",
    "Print the relevant logging message at the end of each associated function call (we will do this later).\n",
    "\n",
    "| Task | Log message on completion |\n",
    "|:----------------------------|:--------------------------------------------------------|\n",
    "| Declaring known values | Preliminaries complete. Initiating ETL process |\n",
    "| Call extract() function | Data extraction complete. Initiating Transformation process |\n",
    "| Call transform() function\t| Data transformation complete. Initiating Loading process |\n",
    "| Call load_to_csv() | Data saved to CSV file |\n",
    "| Initiate SQLite3 connection | SQL Connection initiated |\n",
    "| Call load_to_db()\t| Data loaded to Database as a table, Executing queries |\n",
    "| Call run_query()\t| Process Complete |\n",
    "| Close SQLite3 connection | Server Connection closed |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    # This function logs the mentioned message at a given stage of the code execution to a log file\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) # convert timestamp format to string\n",
    "    with open(\"./code_log.txt\",\"a\") as file: \n",
    "        file.write(timestamp + ' : ' + message + '\\n') # add each log entry in a new line in the txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Extraction of data\n",
    "Identify the position of the required table under the heading 'By market capitalization'. Write the function `extract()` to retrieve the information of the table to a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data_url, table_attribs):\n",
    "    # This function extracts the required information from the website and saves it to a dataframe\n",
    "    # The function returns the dataframe for further processing\n",
    "    page = requests.get(data_url).text # extract the webpage as text\n",
    "    data = BeautifulSoup(page, 'html.parser') # parse the text into an HTML object\n",
    "    df = pd.DataFrame(columns=table_attribs) # create a pandas DataFrame with column argument set as table_attribs\n",
    "    data_dict = dict() # create an empty dictionary \n",
    "    Name_vals = [] # create an empty list that will contain the banks' names\n",
    "    Market_cap_vals = [] # create an empty list that will contain the Market capitalization values\n",
    "    tables = data.find_all('tbody') # find all the tables in the HTML code\n",
    "    rows = tables[0].find_all('tr') # from table number 1 (at index 0), find all rows\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td') # for each row, find all data cells\n",
    "        for cell in cells:\n",
    "            if len(cells) != 0: # check that entries are not empty\n",
    "                Name = cells[1].find_all('a')[1].contents[0] # extract the text content of the index 1 cell, after the second link ('a' tag) \n",
    "                Market_cap = float(cells[2].contents[0][:-1]) # extract the content of index 2 cell, remove the last character, \n",
    "                # and typecast the value to float format\n",
    "                if Name not in Name_vals: # we don't want any duplicates so we check if the bank name is already in the Name_vals list\n",
    "                    Name_vals.append(Name)\n",
    "                    Market_cap_vals.append(Market_cap)\n",
    "                    data_dict = {\"Name\": Name, \"MC_USD_Billion\": Market_cap}\n",
    "                    df1 = pd.DataFrame(data_dict, index=[0]) # create a dataframe from the data_dict dictionary \n",
    "                    df = pd.concat([df,df1], ignore_index=True) # combine dataframes\n",
    "                else: \n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Transformation of data\n",
    "1. Write the function `extract_from_csv()` to read the exchange rate CSV file and convert the contents to a dictionary so that the contents of the first column ('Currency') are the keys to the dictionary and the contents of the second column are the corresponding values ('Rate');\n",
    "2. Write the function `transform()` and add 3 different columns to the dataframe: `MC_GBP_Billion`, `MC_EUR_Billion` and `MC_INR_Billion`, each containing the content of `MC_USD_Billion` scaled by the corresponding exchange rate factor. Round the resulting data to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    csv_df = pd.read_csv(file_to_process, index_col=0)\n",
    "    csv_dict = csv_df.to_dict()['Rate']\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    # This function transforms the Market Capitalization information according to exchange rate in GBP, EUR and INR,\n",
    "    # rounded to 2 decimal places, and adds the respective columns to the dataframe\n",
    "    # The function returns the transformed dataframe\n",
    "    df['MC_GBP_Billion'] = [np.round(x*csv_dict['GBP'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_EUR_Billion'] = [np.round(x*csv_dict['EUR'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_INR_Billion'] = [np.round(x*csv_dict['INR'],2) for x in df['MC_USD_Billion']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Loading to CSV\n",
    "Write the function `load_to_csv()` to load the transformed data frame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, csv_path):\n",
    "    # This function saves the final dataframe as a CSV file in the provided path\n",
    "    df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Loading to Database\n",
    "Write the function `load_to_db()` to load the transformed data frame to an SQL database.\n",
    "\n",
    "Note: Before calling this function, we will initiate the connection to the SQLite3 database server with the name `Banks.db`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    # This function saves the final dataframe as a database table\n",
    "    df.to_sql(table_name, sql_connection, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Run queries on Database\n",
    "Write the function `run_queries()` that accepts the query statement, and the SQLite3 Connection object, and generates the output of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    # This function runs the stated query on the database table and prints the output on the terminal \n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do this!\n",
    "Now let's write the function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(data_url, table_attribs)\n",
    "\n",
    "# Transforming information\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "csv_dict = extract_from_csv('exchange_rate.csv')\n",
    "\n",
    "df = transform(df)\n",
    "\n",
    "# Loading information\n",
    "log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('Banks.db') # Connecting to the SQLite3 database server\n",
    "\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "# Querying the database table \n",
    "log_progress('Data loaded to Database as a table, Executing queries')\n",
    "\n",
    "# Query no. 1: Print the contents of the entire table\n",
    "query_statement1 = f\"SELECT * FROM Largest_banks\"\n",
    "run_query(query_statement1, sql_connection)\n",
    "\n",
    "# Query no. 2: Print the average market capitalization of all the banks in Billion GBP\n",
    "query_statement2 = f\"SELECT AVG(MC_GBP_Billion) FROM Largest_banks\"\n",
    "run_query(query_statement2, sql_connection)\n",
    "\n",
    "# Query no. 3: Print only the names of the top 5 banks\n",
    "query_statement3 = f\"SELECT Name FROM Largest_banks LIMIT 5\"\n",
    "run_query(query_statement3, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "\n",
    "sql_connection.close() # Closing SQLite3 connection\n",
    "\n",
    "log_progress('Server Connection closed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
